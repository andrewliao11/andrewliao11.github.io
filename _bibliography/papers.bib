---
---



@inproceedings{liao2024translating,
  title={Translating Labels to Solve Annotation Mismatches Across Object Detection Datasets},
  author={Yuan-Hong Liao and David Acuna and Rafid Mahmood and James Lucas and Viraj Uday Prabhu and Sanja Fidler},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
  url={https://openreview.net/forum?id=ChHx5ORqF0}, 
  selected={true}
}
@article{prabhu2023bridging,
  title={Bridging the Sim2Real gap with {CARE}: Supervised Detection Adaptation with Conditional Alignment and Reweighting},
  author={Viraj Uday Prabhu and David Acuna and Rafid Mahmood and Marc T. Law and Yuan-Hong Liao and Judy Hoffman and Sanja Fidler and James Lucas},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2023},
  url={https://openreview.net/forum?id=lAQQx7hlku},
  note={}
}
@inproceedings{pal2021emergent,
  title={Emergent Road Rules In Multi-Agent Driving Environments},
  author={Avik Pal and Jonah Philion and Yuan-Hong Liao and Sanja Fidler},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=d8Q1mt2Ghw}
}

@InProceedings{Liao_2021_CVPR,
    author    = {Liao, Yuan-Hong and Kar, Amlan and Fidler, Sanja},
    title     = {Towards Good Practices for Efficiently Annotating Large-Scale Image Classification Datasets},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {4350-4359}
    selected={true}
}
@inproceedings{pal2021emergent,
  title={Emergent Road Rules In Multi-Agent Driving Environments},
  author={Avik Pal and Jonah Philion and Yuan-Hong Liao and Sanja Fidler},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=d8Q1mt2Ghw}
}
@inproceedings{puig2021watchandhelp,
  title={Watch-And-Help: A Challenge for Social Perception and Human-{\{}AI{\}} Collaboration},
  author={Xavier Puig and Tianmin Shu and Shuang Li and Zilin Wang and Yuan-Hong Liao and Joshua B. Tenenbaum and Sanja Fidler and Antonio Torralba},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=w_7JMpGZRh0}
}

@InProceedings{Liao_2019_CVPR,
  author = {Liao, Yuan-Hong and Puig, Xavier and Boben, Marko and Torralba, Antonio and Fidler, Sanja},
  title = {Synthesizing Environment-Aware Activities via Activity Sketches},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2019}
}

@InProceedings{Sun_2018_ECCV,
  author = {Sun, Shao-Hua and Huh, Minyoung and Liao, Yuan-Hong and Zhang, Ning and Lim, Joseph J.},
  title = {Multi-view to Novel view: Synthesizing novel views with Self-Learned Confidence},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  month = {September},
  year = {2018}
}

@inproceedings{ijcai2017p525,
   author    = {Yen-Chen Lin and Zhang-Wei Hong and Yuan-Hong Liao and Meng-Li Shih and Ming-Yu Liu and Min Sun},
   title     = {Tactics of Adversarial Attack on Deep Reinforcement Learning Agents},
   booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on
                Artificial Intelligence, {IJCAI-17}},
   pages     = {3756--3762},
   year      = {2017},
   doi       = {10.24963/ijcai.2017/525},
   url       = {https://doi.org/10.24963/ijcai.2017/525},
   abstract  = {We introduce two tactics, namely the strategically-timed attack and the enchanting attack, to attack reinforcement learning agents trained by deep reinforcement learning algorithms using adversarial examples. In the strategically-timed attack, the adversary aims at minimizing the agent's reward by only attacking the agent at a small subset of time steps in an episode. Limiting the attack activity to this subset helps prevent detection of the attack by the agent. We propose a novel method to determine when an adversarial example should be crafted and applied. In the enchanting attack, the adversary aims at luring the agent to a designated target state. This is achieved by combining a generative model and a planning algorithm: while the generative model predicts the future states, the planning algorithm generates a preferred sequence of actions for luring the agent. A sequence of adversarial examples is then crafted to lure the agent to take the preferred sequence of actions. We apply the proposed tactics to the agents trained by the state-of-the-art deep reinforcement learning algorithm including DQN and A3C. In 5 Atari games, our strategically-timed attack reduces as much reward as the uniform attack (i.e., attacking at every time step) does by attacking the agent 4 times less often. Our enchanting attack lures the agent toward designated target states with a more than 70% success rate. Example videos are available at http://yclin.me/adversarial_attack_RL/.}, 
   html = {http://yenchenlin.me/adversarial_attack_RL/},
   paper = {https://arxiv.org/abs/1703.06748},
 }
 @article{
  Zeng_Chen_Chuang_Liao_Niebles_Sun_2017, 
  title={Leveraging Video Descriptions to Learn Video Question Answering}, 
  volume={31}, 
  url={https://ojs.aaai.org/index.php/AAAI/article/view/11238}, 
  DOI={10.1609/aaai.v31i1.11238},    
  abstractNote={ &lt;p&gt; We propose a scalable approach to learn video-based question answering (QA): to answer a free-form natural language question about the contents of a video. Our approach automatically harvests a large number of videos and descriptions freely available online. Then, a large number of candidate QA pairs are automatically generated   from descriptions rather than manually annotated. Next, we use these candidate QA pairs to train a number of video-based  QA methods extended from MN (Sukhbaatar et al. 2015), VQA (Antol et al. 2015), SA (Yao et al. 2015), and SS (Venugopalan  et al. 2015). In order to handle non-perfect candidate QA pairs, we propose a self-paced learning procedure to iteratively identify them and mitigate their effects in training. Finally, we evaluate performance on manually generated  video-based QA pairs. The results show that our self-paced learning procedure is effective, and the extended SS model outperforms various baselines. &lt;/p&gt; }, 
  number={1}, 
  journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
  author={Zeng, Kuo-Hao and Chen, Tseng-Hung and Chuang, Ching-Yao and Liao, Yuan-Hong and Niebles, Juan Carlos and Sun, Min}, 
  year={2017}, 
  month={Feb.} 
}
@InProceedings{Chen_2017_ICCV,
  author = {Chen, Tseng-Hung and Liao, Yuan-Hong and Chuang, Ching-Yao and Hsu, Wan-Ting and Fu, Jianlong and Sun, Min},
  title = {Show, Adapt and Tell: Adversarial Training of Cross-Domain Image Captioner},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  month = {Oct},
  year = {2017}
}